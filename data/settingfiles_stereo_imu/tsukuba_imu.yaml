%YAML:1.0
# the world frame is the left camera frame (right, down, forward) at startIndex

startIndex: 1
finishIndex: 1800
dataset: "Tsukuba" # choose one of KITTISeq00, Tsukuba, MalagaUrbanExtract6
use_imu_data: true

input_path: /media/jhuai/Mag/NewTsukubaStereoDataset/illumination/daylight 
voc_file_path: /home/jhuai/catkin_ws/src/ORB_SLAM2/Vocabulary/ORBvoc.txt
output_file: /home/jhuai/Desktop/temp/tsukuba_imu.txt
output_point_file: /home/jhuai/Desktop/temp/tsukuba_imu_points.txt
imu_file: "/home/jhuai/catkin_ws/src/orbslam_dwo/data/tsukuba_imu_samplesnoisy.txt"  #samples added noise generated according to Microstrain 3DM-GX3-35

trace_dir: "/home/jhuai/catkin_ws/src/orbslam_dwo/data/result" # where to put the slam profiled time

sample_interval: 0.01
na: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [80e-5, 80e-5, 80e-5 ] # 80 ug with 1 Hz 
# q_na=na^2
nw: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [0.03, 0.03, 0.03] # 0.03 deg/sec/sqrt(Hz) 
#q_nw=(nw*pi/180)^2
acc_bias_Tc: 1800       #sec
acc_bias_var: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [.04e-2, .04e-2, .04e-2]#bias drift variability, 0.04 mg
#q_n_ba=(.04e-2)^2*(2/acc_bias_Tc);
gyro_bias_Tc: 1800 #sec
gyro_bias_var: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [5e-3, 5e-3, 5e-3]#bias drift variability, 18 deg/hour
#q_n_bw=(18*(pi/180.0)/3600)^2*(2/gyro_bias_Tc); # 18deg/hr  
# rotation from IMU frame (forward, right, down) to camera frame(right, down, forward),
Rs2c: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [ 0, 1, 0, 0, 0, 1, 1, 0, 0 ]
tsinc: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [ 0.05, -0.06, 0.02 ] # N.B. camera_track.txt of Tsukuba used a central camera frame, in our program, we use left camera frame

gw: !!opencv-matrix # gravity in the local world frame
   rows: 3
   cols: 1
   dt: f
   data: [ -0.000295986886093669, 9.80080743561639,  -1.24212161392023e-05]
wiew: !!opencv-matrix # earth rotation in the local world frame
   rows: 3
   cols: 1
   dt: d
   data: [   0,  -4.68759582209682e-05 , 5.58582013511762e-05]

#vs0inw: velocity of IMU frame in world frame at startIndex
vs0inw: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [ 5.66554e-05, -4.80246e-05, 0.000643521]


# Camera calibration parameters (OpenCV) 
Camera.width: 640
Camera.height: 480
Camera.fx: 615
Camera.fy: 615 
Camera.cx: 320
Camera.cy: 240

# Camera distortion paremeters (OpenCV) --
Camera.k1: 0
Camera.k2: 0
Camera.p1: 0.0
Camera.p2: 0.0

Stereo.se3Left2Right: !!opencv-matrix
   rows: 4
   cols: 4
   dt: f
   data: [ 1, 0, 0, -0.1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]

Stereo.matRightK: !!opencv-matrix
   rows: 3
   cols: 3
   dt: f
   data: [ 615, 0, 320, 0, 615, 240, 0, 0, 1]
# Stereo.matRightDistCoef: k1 k2 p1 p2 (Opencv)
Stereo.matRightDistCoef: !!opencv-matrix
   rows: 4
   cols: 1
   dt: f
   data: [ 0, 0, 0, 0]

# Camera frames per second 
Camera.fps: 30.0

# Color order of the images (0: BGR, 1: RGB. It is ignored if images are grayscale)
Camera.RGB: 1

#--------------------------------------------------------------------------------------------
### Changing the parameters below could seriously degradate the performance of the system

# ORB Extractor: Number of features per image
ORBextractor.nFeatures: 500

# ORB Extractor: Scale factor between levels in the scale pyramid 	
ORBextractor.scaleFactor: 1.2

# ORB Extractor: Number of levels in the scale pyramid	
ORBextractor.nLevels: 1

# ORB Extractor: Fast threshold (lower less restrictive)			
ORBextractor.fastTh: 20

# ORB Extractor: Score to sort features. 0 -> Harris Score, 1 -> FAST Score			
ORBextractor.nScoreType: 1
